{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LiTWcREfPKRg"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from copy import deepcopy as dc\n",
    "import tqdm\n",
    "import time\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.orca.config.use_xvfb = True\n",
    "\n",
    "pio.orca.config.executable = 'path/orca'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5u2kiFdYQkiT",
    "outputId": "3fb8f291-8102-4e71-cfad-61828c4b0ee3"
   },
   "outputs": [],
   "source": [
    "CUDA_DEVICE = 1\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.device(CUDA_DEVICE))\n",
    "print(torch.device(CUDA_DEVICE))\n",
    "print(torch.cuda.get_device_name(CUDA_DEVICE))\n",
    "print(torch.cuda.current_device())\n",
    "\n",
    "device = torch.device(CUDA_DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"name\",\n",
    "    name=\"MAE\", \n",
    "\n",
    "    config={\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"architecture\": \"LSTM\",\n",
    "    \"dataset\": \"30min\",\n",
    "    \"epochs\": 100,\n",
    "    }\n",
    ")\n",
    "\n",
    "wandb.define_metric(\"MAE\", summary=\"min\")\n",
    "wandb.define_metric(\"MASE\", summary=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "dbqI7xmIPKRj",
    "metadata": {},
    "outputId": "e21069fe-d25a-46fb-a1d6-b52d37ceafa5"
   },
   "outputs": [],
   "source": [
    "data = pd.read_pickle('dataset')\n",
    "\n",
    "n = len(data)\n",
    "data.insert(0, 'time_series', list(range(1, n+1)))\n",
    "data = data[['time_series', '30m-item71']]\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1)\n",
    "fig.append_trace(go.Scatter(\n",
    "                            x=data.index,\n",
    "                            y=data['30m-item71'].values,\n",
    "                            name=\"test\",\n",
    "                            line_color='blue'\n",
    "                        ), row=1, col=1),\n",
    "fig.update_layout(\n",
    "    font_family=\"Gyre Bonum\",\n",
    "    margin=dict(\n",
    "    l=20,\n",
    "    r=10,\n",
    "    b=20,\n",
    "    t=10,\n",
    "    pad=4\n",
    "),)\n",
    "fig.show(renderer='iframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "mXR15E3XPKRk",
    "jupyter": {
     "outputs_hidden": true
    },
    "metadata": {},
    "outputId": "e33229ef-e391-413e-b821-07e3a94eb864",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy as dc\n",
    "\n",
    "def prepare_dataframe_for_lstm(df, n_steps):\n",
    "    df = dc(df)\n",
    "\n",
    "    df.set_index('time_series', inplace=True)\n",
    "\n",
    "    for i in range(1, n_steps+1):\n",
    "        df[f'30m(t-{i})'] = df['30m-item71'].shift(i)\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "shifted_df = prepare_dataframe_for_lstm(data, 384)\n",
    "shifted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tv8GE1toPKRl",
    "metadata": {},
    "outputId": "0932128c-aa15-4149-df97-937ff87b6365",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train1 = shifted_df[27:15549]\n",
    "train2 = shifted_df[15602:16602]\n",
    "train = np.concatenate((train1, train2))\n",
    "\n",
    "pandas_train = pd.DataFrame(train)\n",
    "\n",
    "shiftet_real_unscaled = train2['30m-item71'].shift()\n",
    "diffs = train2['30m-item71'] - shiftet_real_unscaled\n",
    "avg_diff_unscaled = torch.as_tensor(diffs.abs().mean()).to(device)\n",
    "print(avg_diff_unscaled)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "std_scaler = MinMaxScaler(feature_range=(1, 5))\n",
    "std_scaler.fit(train)\n",
    "data_scaled = std_scaler.transform(shifted_df)\n",
    "\n",
    "data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "seguZsU-PKRm",
    "metadata": {},
    "outputId": "b24673de-efea-44dc-93cb-eb0f3ae64509"
   },
   "outputs": [],
   "source": [
    "X = data_scaled[:, 1:]\n",
    "y = data_scaled[:, 0]\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HwT0yOPMfX4y",
    "outputId": "7bb874ee-df56-4742-aaea-33df4fd44060"
   },
   "outputs": [],
   "source": [
    "first_elements = X[:, [0]].reshape(-1)\n",
    "\n",
    "differences = np.abs(np.subtract(first_elements, np.roll(first_elements, -1)))\n",
    "avg_diff_scaled = differences[:-1].mean()\n",
    "avg_diff_scaled = torch.as_tensor(avg_diff_scaled).to(device)\n",
    "avg_diff_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s8HZArHsPKRn",
    "metadata": {},
    "outputId": "99dbabf7-dd88-475b-cedd-cb75b3e494de"
   },
   "outputs": [],
   "source": [
    "X_train1 = X[27:15549]\n",
    "X_train2 = X[15602:16602]\n",
    "X_train = np.concatenate((X_train1, X_train2))\n",
    "X_test = X[16602-384-1:17459]\n",
    "\n",
    "y_train1 = y[27:15549]\n",
    "y_train2 = y[15602:16602]\n",
    "y_train = np.concatenate((y_train1, y_train2))\n",
    "y_test = y[16602-384-1:17459]\n",
    "\n",
    "train_size = y_train.shape\n",
    "test_size = y_test.shape\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PYtuP1DQPKRn",
    "metadata": {},
    "outputId": "aed43337-37c8-4ac1-c62f-9602d67729a4"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((-1, lookback, 1))\n",
    "X_test = X_test.reshape((-1, lookback, 1))\n",
    "\n",
    "y_train = y_train.reshape((-1, 1))\n",
    "y_test = y_test.reshape((-1, 1))\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6dlvk5jxPKRo",
    "metadata": {},
    "outputId": "eceb38ad-30b0-401a-b630-2e5b1304b486"
   },
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train).float()\n",
    "y_train = torch.tensor(y_train).float()\n",
    "X_test = torch.tensor(X_test).float()\n",
    "y_test = torch.tensor(y_test).float()\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "x-IKENpfPKRo",
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]\n",
    "\n",
    "train_dataset = TimeSeriesDataset(X_train, y_train)\n",
    "test_dataset = TimeSeriesDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "9J3AspVqPKRo",
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wd83MlBEPKRo",
    "metadata": {},
    "outputId": "0f5c3822-cf6f-49ce-f6cb-e046a022bd0c"
   },
   "outputs": [],
   "source": [
    "for _, batch in enumerate(train_loader):\n",
    "    x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "    print(x_batch.shape, y_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_stacked_layers, dropout_rate):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size, hidden_size, num_stacked_layers, batch_first=True, dropout=dropout_rate\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "model = LSTM(1, 128, 3, 0.1)\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "JU1XAGOOPKRp",
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def train_one_epoch():\n",
    "    model.train(True)\n",
    "    print(f'Epoch: {epoch + 1}')\n",
    "    epoch_loss = 0.0\n",
    "    epoch_metrics = 0.0\n",
    "    \n",
    "    loop = tqdm.tqdm(train_loader)\n",
    "\n",
    "    for batch_index, batch in enumerate(loop, 1):\n",
    "        x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "        output = model(x_batch)\n",
    "        \n",
    "        # loss = loss_function(output, y_batch)\n",
    "        loss = custom_loss(output, y_batch, x_batch[:,-1,:])\n",
    "\n",
    "        metrics = nn.functional.l1_loss(output, y_batch)\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_metrics += metrics.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    return epoch_loss, epoch_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Qtu2kKVAPKRq",
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def validate_one_epoch():\n",
    "    model.train(False)\n",
    "    running_loss = 0.0\n",
    "    running_metrics = 0.0\n",
    "\n",
    "    for batch_index, batch in enumerate(test_loader):\n",
    "        x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(x_batch)\n",
    "            \n",
    "            loss = custom_loss(output, y_batch, x_batch[:,-1,:])\n",
    "            # loss = loss_function(output, y_batch)\n",
    "            \n",
    "            metrics = nn.functional.l1_loss(output, y_batch)\n",
    "            \n",
    "            running_loss += loss.item() * len(x_batch)\n",
    "            running_metrics += metrics.item() * len(x_batch)\n",
    "            wandb.log({\"acc\": metrics, \"loss\": loss})\n",
    "\n",
    "    avg_loss_across_batches = running_loss / len(test_loader)\n",
    "    avg_metrics_across_batches = running_metrics / len(test_loader)\n",
    "\n",
    "    print('Val Loss: {0:.3f}'.format(avg_loss_across_batches))\n",
    "    print('Metrics val Loss: {0:.3f}'.format(avg_metrics_across_batches))\n",
    "    print('-------------------------------------------------')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "s-9FFZQ-PKRq"
   },
   "outputs": [],
   "source": [
    "def custom_loss(pred, real, real_minus1):\n",
    "    dPR = torch.abs(real - pred)\n",
    "    dPRM = torch.sqrt(avg_diff_scaled**2 + (pred - real_minus1)**2)\n",
    "    dRRM = torch.sqrt(avg_diff_scaled**2 + (real - real_minus1)**2)\n",
    "    cosR = (dPRM**2 + dRRM**2 - dPR**2)/(2*dPRM*dRRM)\n",
    "    cosR = torch.clamp(cosR, -0.999999, 0.999999)\n",
    "    loss =  torch.mean(torch.arccos(cosR))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(output, target):\n",
    "    eps = 1e-8\n",
    "    loss = torch.mean(torch.sqrt(eps + (output - target)**2))\n",
    "    return loss\n",
    "\n",
    "def msle(output, target):\n",
    "    output = torch.clamp(output, 0, 5)\n",
    "    target = torch.clamp(target, 0, 5)\n",
    "    loss = torch.mean(((torch.log(1 + output) - torch.log(1 + target)))**2)\n",
    "    return loss\n",
    "\n",
    "def mase(output, target):\n",
    "    loss = torch.mean(torch.abs(output-target) / avg_diff_scaled)\n",
    "    return loss\n",
    "\n",
    "def rmsse(output, target):\n",
    "    eps = 1e-8\n",
    "    loss = torch.mean(torch.sqrt(eps + ((output - target)**2) / avg_diff_scaled**2))\n",
    "    return loss\n",
    "\n",
    "def poisson(output, target):\n",
    "    output = torch.clamp(output, 0, 5)\n",
    "    target = torch.clamp(target, 0, 5)\n",
    "    loss = torch.mean(output - target * torch.log(output) + torch.log(torch.exp(torch.lgamma(target + 1))))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def logCosh(output, target):\n",
    "    output = torch.clamp(output, 0, 5)\n",
    "    target = torch.clamp(target, 0, 5)\n",
    "    loss = torch.mean(torch.log(torch.cosh(output - target)))\n",
    "    return loss\n",
    "\n",
    "def mape(output, target):\n",
    "    loss = torch.mean(torch.abs(target - output) / torch.abs(target))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "he3FMQBiPKRr",
    "metadata": {},
    "outputId": "eef6c2e0-5a69-444d-e237-5a7fe2e7caef",
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "loss_function = \"function name\"\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_one_epoch()\n",
    "    validate_one_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wK-tx0TCPKRr",
    "jupyter": {
     "source_hidden": true
    },
    "metadata": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    predicted = model(X_train.to(device)).to('cuda:0').numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "YB_0tKFwPKRs",
    "metadata": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_predictions = model(X_test.to(device)).detach().cpu().numpy().flatten()\n",
    "\n",
    "\n",
    "dummies = np.zeros((X_test.shape[0], lookback+1))\n",
    "dummies[:, 0] = test_predictions\n",
    "dummies = std_scaler.inverse_transform(dummies)\n",
    "\n",
    "test_predictions = dc(dummies[:, 0])\n",
    "\n",
    "dummies = np.zeros((X_test.shape[0], lookback+1))\n",
    "dummies[:, 0] = y_test.flatten()\n",
    "dummies = std_scaler.inverse_transform(dummies)\n",
    "\n",
    "new_y_test = dc(dummies[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_unscaled = torch.tensor(test_predictions)\n",
    "train_unscaled = torch.tensor(new_y_test)\n",
    "\n",
    "train_size = y_train.shape[0]\n",
    "test_size = y_test.shape[0]\n",
    "\n",
    "def metric_mase(output, target):\n",
    "    MAE = torch.mean(torch.abs(output-target))\n",
    "    return MAE / avg_diff_unscaled\n",
    "\n",
    "mae_loss_metric = nn.functional.l1_loss(predicted_unscaled, train_unscaled)\n",
    "print(mae_loss_metric.item())\n",
    "\n",
    "mase_loss_metric = metric_mase(predicted_unscaled, train_unscaled)\n",
    "print(mase_loss_metric.item())\n",
    "\n",
    "log_dict = {\n",
    "        \"MAE\": mae_loss_metric,\n",
    "        \"MASE\": mase_loss_metric,\n",
    "    }\n",
    "wandb.log(log_dict)\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TuKHlTq6PKRs",
    "metadata": {},
    "outputId": "353f1705-6871-4f73-b705-7d9f7094a418",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_test = pd.DataFrame({'pred': test_predictions, 'real': new_y_test}, columns=['pred', 'real'])\n",
    "dataset_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_predikovane_3_parts = [dataset_test.iloc[:285], \n",
    "                       dataset_test.iloc[285:285+285], \n",
    "                       dataset_test.iloc[285+285:]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(predictions, colors):\n",
    "    fig = make_subplots(rows=1, cols=1)\n",
    "\n",
    "    for i in range(len(predictions.columns)):\n",
    "        \n",
    "        if i == 0: \n",
    "            opacity = 1\n",
    "        else:\n",
    "            opacity = 0.7\n",
    "        fig.append_trace(go.Scatter(\n",
    "                            x=predictions.index,\n",
    "                            y=predictions[predictions.columns[i]].values,\n",
    "                            name=predictions.columns[i],\n",
    "                            line=dict(color=colors[i], width=1.5),\n",
    "                            opacity=opacity\n",
    "                        ), row=1, col=1)\n",
    "    \n",
    "    fig.update_layout(\n",
    "                font_family=\"Gyre Bonum\",\n",
    "        font_size=20,\n",
    "        xaxis_title=\"Čas\",\n",
    "        yaxis_title=\"Počet útokov\",\n",
    "        margin=dict(\n",
    "        l=20,\n",
    "        r=20,\n",
    "        b=20,\n",
    "        t=20,\n",
    "        pad=4\n",
    "    ),\n",
    "        height=300, \n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data_predikovane_3_parts)):\n",
    "    nakres_more = draw(data_predikovane_3_parts[i][\n",
    "        ['real', 'pred']\n",
    "        ], [\"blue\", \"red\"])\n",
    "    nakres_more.show(renderer='iframe')\n",
    "    pio.write_image(nakres_more, 'path/Loss_naem{}.eps'.format([i]), width=2000, height=600, format='eps'\n",
    "                    , engine='kaleido' \n",
    "                    )\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "bc",
   "language": "python",
   "name": "bc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
